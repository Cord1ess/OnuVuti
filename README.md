# OnuVuti (‡¶Ö‡¶®‡ßÅ‡¶≠‡ßÇ‡¶§‡¶ø)

**One Universal Language. One Universal Connection.**

OnuVuti is a sensory-adaptive communication hub designed for the next generation of inclusive interactions. Built with a high-energy **Neobrutalist (Dorksense)** aesthetic, it enables users with visual, hearing, or vocal impairments to connect through a shared, modal-transparent interface.

## üöÄ Key Features

### 1. Universal Communication Hub

- **Resonance Matching**: Pairs users randomly using a cross-impairment translation engine.
- **Sensory Translation**: Automatically converts signals (e.g., Emoji ‚Üí Haptic + TTS) based on recipient needs.
- **Live Link Architecture**: Real-time feedback via visual pulses, haptic patterns, and voice synthesis.

### 2. Interaction Rehaul (Sensory Tools)

- **Haptic Sight (Blind)**: Interactive cursor scanning that describes the UI via sound and vibration.
- **Visual Hearing (Deaf)**: A high-fidelity reactive waveform visualizer for rhythmic audio feedback.
- **Expression Composer (Mute)**: A categorised intent-engine for building complex non-verbal messages.

### 3. Progressive Accessibility

- **Tactile Mastery**: Specialized vibration signatures for Blind+Deaf users.
- **Glitch Mode**: High-energy visual transitions that double as status indicators.
- **Inclusive UI Map**: 100% coverage for non-visual navigation via `data-haptic-label`.

## üõ†Ô∏è Technical Stack

- **Framework**: React + Vite
- **Styling**: Vanilla CSS + Tailwind (Neobrutalist System)
- **Sensors**: Web Speech API, Vibration API, Canvas API
- **Design**: Dorksense Architecture (Aggressive borders, grainy textures, vibrant contrast)

## üé® Aesthetic

OnuVuti embraces the **Neobrutalist** philosophy‚ÄîUI that is raw, high-contrast, and unapologetically accessible. It uses custom cursors, chromatic aberration glitch effects, and a pervasive grain overlay to create a premium, tactile feel.

---

_Winner of the Sensory Innovation Hackathon Concept (Simulated)._
