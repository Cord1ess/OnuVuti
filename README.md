# OnuVuti (অনুভূতি)

## Problem Statement

Traditional digital communication interfaces rely heavily on text and complex visual hierarchies, creating significant barriers for individuals with sensory impairments. Visual, auditory, and vocal limitations often prevent seamless interaction with mainstream social and collaborative platforms. There is a critical need for a non-verbal, high-contrast, and sensor-driven interface that prioritizes accessibility through haptic, audio, and simplified visual cues.

## Features

### Non-Verbal Communication Interface

- Gesture-based interaction system for users with vocal impairments.
- High-contrast Neobrutalist design system optimizing visibility for users with visual impairments.
- Visual-only notification and feedback loops for deaf and hard-of-hearing users.

### Sensory Integration

- Haptic Feedback Engine: Standardized vibration patterns for interface actions and status updates.
- Speech Synthesis Integration: Audio cues for all navigational and interactive elements.
- Custom Cursor Control: Morphing cursor states for enhanced interactive focus.

### Accessibility Architecture

- Context-aware UI: Dynamic interface adjustment based on selected user impairment profiles.
- Zero-Text Interaction: Prioritization of icons, colors, and motion over verbal instructions.
- Pre-loader and Experience Smoothing: Optimized loading states to reduce cognitive load.

### Technical Implementation

- Built with React, TypeScript, and Vite for high-performance rendering.
- Tailwind CSS custom design system for consistent Neobrutalist aesthetics.
- GSAP and Canvas Confetti for high-quality interactive feedback.
