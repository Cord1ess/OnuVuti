# OnuVuti (‡¶Ö‡¶®‡ßÅ‡¶≠‡ßÇ‡¶§‡¶ø)

**One Universal Language. One Universal Connection.**

OnuVuti is a sensory-adaptive communication hub designed for the next generation of inclusive interactions. Built with a high-energy **Neobrutalist (Dorksense)** aesthetic, it enables users with visual, hearing, or vocal impairments to connect through a shared, modal-transparent interface.

### 1. Universal Resonance Hub

- **Resonance Matching**: Pairs users in real-time rooms via Node.js/Socket.io.
- **Sensory Translation**: Automatically converts signals (e.g., Emoji ‚Üí Haptic + TTS) based on recipient needs.
- **Expressive Media**: Full Tenor GIF integration with haptic/auditory descriptions for accessibility.

### 2. Interaction Rehaul (Sensory Tools)

- **Mediator Agent (OnuVuti-Core)**: An invisible AI layer that monitors interaction balance, detects emotional confusion, and triggers subtle grounding nudges.
- **Haptic Sight (Blind)**: Interactive cursor scanning that describes the UI via sound and vibration.
- **Visual Hearing (Deaf)**: A high-fidelity reactive waveform visualizer and tactile Braille vibration engine.
- **Expression Hub (Mute)**: Intent-engine for building complex non-verbal messages and voice-to-text projection.

## üõ†Ô∏è Technical Stack

- **Frontend**: React + Vite
- **Backend**: Node.js + Socket.io (Real-time Signal Relay)
- **API**: Tenor API (Expressive Media Proxy)
- **Sensors**: Web Speech API, Vibration API, Canvas API, Face-API.js (Expression Recognition)
- **Design**: Neobrutalist System (High-contrast, Aggressive borders, Grainy textures)

---

_A premium, high-energy accessibility project built for the age of resonance._
